
Plan: “Assess by Word” (Design v1)`n0) Constraints &amp; Reuse`nKeep UI consistent with your current Dashboard → Grammar DB Update → “Assess by Word”.`nReuse the existing “Assess by Verse” analysis window to perform verse-level tagging; “Assess by Word” is an orchestration layer that feeds it a curated queue of verses for the chosen word(s).`nLean on your existing normalization helpers (e.g., NFC + danda stripping) when matching tokens so results don’t drift due to invisible glyphs. `n`n1) UX Flow`nA) Landing (Assess by Word Dashboard)`nButtons:`nNew assessment`nContinue incomplete`nView completed`nB) New assessment`nWord search modal`nInput: one word (single token).`n“Search” queries 1.1.3 sggs_extracted_with_page_numbers.xlsx → returns deduped closest matches (RapidFuzz partial/token sort ratio), shown as a tick-list.`nAllow multi-select; if &gt;1 selected, open a Sequence step:`nSimple up/down arrow controls (or small “rank” spinboxes) to set order.`nTracker file initialization`nEnsure an Excel workbook named 1.1.6 XXXX.xlsx exists (XXXX = configurable label like “AssessByWordTracker” or a date tag).`nSheet 1 — Words (queue level)`nColumns (suggested):`nword, word_key_norm, listed_by_user (bool), listed_at,`nselected_for_analysis (bool), selected_at,`nanalysis_started (bool), analysis_started_at,`nanalysis_completed (bool), analysis_completed_at,`nsequence_index (int), notes`nWrite/append all selected words with timestamps and sequence_index.`nKick-off`nOpen the first word (lowest sequence_index with analysis_completed == False) into the Analysis view (section C).`nC) Analysis (for one chosen word)`nVerse picker for the word`nQuery 1.1.3 sggs_extracted_with_page_numbers.xlsx for exact token matches in Verse (respect word boundaries; use your _norm_tok equivalent for Punjabi tokens).`nShow a scrollable list of verse cards (you can reuse your _populate_cards visual vibe, but without limiting to 10). Include Page Number. Add checkboxes per verse.`n“Add to queue” writes selections into Sheet 2 — Progress (see schema below) and marks selected_for_analysis for the word in Words.`nDrive verse-by-verse analysis`nPresent a Next Verse flow: each chosen verse opens your existing Assess-by-Verse UI, and upon completion, mark progress.`nOn finishing all selected verses for this word:`nIf at least one verse is completed, set analysis_started=True (first completion sets the timestamp if not already set). If all chosen verses are completed, set analysis_completed=True and time.`nPause / Resume`nProvide a Pause button to return to dashboard. State is fully persisted in 1.1.6 XXXX.xlsx.`nD) Continue incomplete`nLoad Words where analysis_completed == False, FIFO by listed_at, display as a list.`nUser clicks a word → jump into its Analysis view loading remaining verses from Progress that are status != completed.`nE) View completed`nLoad from Progress, compute word completion, and list (word, verse, page, completion time) ascending by completion time.`nProvide Re-analyze checkboxes next to any completed verse:`nIf re-analyzed, overwrite the completion_time in Progress for that row, and (optionally) set a reanalyzed_count and latest timestamp.`n`n2) Data model (Excel workbook 1.1.6 XXXX.xlsx)`nSheet 1: Words`nword (str) — exact UI word`nword_key_norm (str) — normalized key (NFC, danda-stripped, trimmed, lowercased)`nlisted_by_user (bool) — initial listing`nlisted_at (datetime)`nselected_for_analysis (bool)`nselected_at (datetime)`nanalysis_started (bool)`nanalysis_started_at (datetime)`nanalysis_completed (bool)`nanalysis_completed_at (datetime)`nsequence_index (int)`nnotes (str)`nSheet 2: Progress`nword (str)`nword_key_norm (str)`nword_index (int) — 0-based position in the verse’s tokens if you want positional tracking; else keep NA`nverse (str)`npage_number (str/int) — from 'Page Number' in the source xlsx`nselected_for_analysis (bool)`nselected_at (datetime)`nstatus (enum: not started | completed)`ncompleted_at (datetime)`nreanalyzed_count (int, default 0)`nlast_reanalyzed_at (datetime or NA)`nAll verse-level results persist exactly like “Assess by Verse” into 1.1.1_birha.csv. Your new flow just drives the verse analyzer and mirrors state in Progress.`n`n3) Matching &amp; Search`nWord search (new assessment):`nUse RapidFuzz to suggest close unique words present across all verses:`nPre-index 1.1.3 …xlsx: for each verse, tokenize to Punjabi words, normalize tokens, aggregate to a Counter and a set of unique forms.`nGiven user input w, compute fuzzy ratios against the unique lexicon, sort by score, show top N (e.g., 100) with counts.`nExact verse hits (analysis):`nFor a selected word, re-scan 1.1.3 …xlsx rows:`nTokenize verse → find rows where any token normalized equals word_key_norm.`nRecord (verse, page_number) for list and for Progress rows.`nNormalization rules: mirror your verse normalization style (NFC, strip dandā, collapse spaces, remove zero-width chars), and add token boundary matching to avoid partials. (This parallels your existing _norm_tok and _verse_key philosophy.) `n`n4) Key Functions (Python/Tk + pandas/openpyxl)`nFilesystem &amp; tracker`ntracker_path = ensure_tracker('1.1.6 XXXX.xlsx')`nload_words(tracker_path) -&gt; DataFrame`nload_progress(tracker_path) -&gt; DataFrame`nappend_words(rows)`nappend_progress(rows)`nupdate_words_status(word_key_norm, **flags_and_timestamps)`nupdate_progress_status(word_key_norm, verse_key, status, timestamp, reanalyze=False)`nWord lexicon &amp; search`nbuild_lexicon_from_sggs(xlsx_path) -&gt; dict[word_key_norm] = { 'display': set(forms), 'count': int }`nfuzzy_find_words(query, lexicon, limit=100) -&gt; list of {display_form, score, count}`nVerse hits for a word`nfind_verses_for_word(xlsx_path, word_key_norm) -&gt; list of {verse, page}`nUse tokenization and normalized comparison; dedup by (norm_verse_key, page).`nSequencing`nassign_sequence(words_selected) -&gt; enumerate to sequence_index`nAnalysis driver`nnext_verse_to_analyze(word_key_norm) -&gt; row from Progress with status != completed`nlaunch_assess_by_verse(verse, page) → call your existing verse-analysis entry point, then on success:`nwrite to 1.1.1_birha.csv (as already done today),`nupdate Progress.completed_at and status='completed',`nif first completion for this word, set Words.analysis_started*,`nif all verses complete, set Words.analysis_completed*.`n`n5) UI Sketch (minimal surgery)`nIn Grammar DB Update window:`nEnable the “Assess by Word” button and route to a new launch_word_assessment_dashboard().`nDashboard frame with the three buttons and short copy.`nFor New, open a modal:`nEntry + Search → checkbox list → Next → sequence order modal → Confirm → writes Sheet 1 → navigate to Analysis view.`nFor Continue, simple table from Words filtered to incomplete; click to jump into Analysis.`nFor Completed, table grouped by word with per-verse rows; include a “Re-analyze” button to push those verses back through the same analyzer.`nYou can borrow the look-and-feel scaffolding from launch_verse_assessment() and _populate_cards() so the new view feels native. `n`n6) Edge Cases &amp; Guards`nDuplicate words: use word_key_norm uniqueness; merge rows when re-listed; only update sequence_index if explicitly re-ordered.`nVerse edits upstream: key verses by a norm_verse_key (your verse normalization) + page_number to remain stable across whitespace tweaks.`nPartial selection: if a user selects 0 verses for a word, keep selected_for_analysis=True but analysis_started=False. Nudge user to add verses when resuming.`nRe-analysis: increment reanalyzed_count and refresh completed_at (and last_reanalyzed_at) so “View completed” stays truthful.`nCrash-safety: every button that advances state writes to Excel first; avoid in-memory-only queues.`n`n7) Performance Notes`nPre-index tokens of 1.1.3 …xlsx once per session (cache in memory). The file is static during a session; refresh button can rebuild.`nFor verse lists, lazy-paginate UI (e.g., 100 at a time) if the word is extremely common.`n`n8) “Definition of Done”`nUsers can:`nStart a new word assessment, queue words, and set sequence.`nPick verses for each word, analyze them using the existing Verse analyzer, and see statuses update live in 1.1.6 XXXX.xlsx.`nResume incomplete words with the next pending verse ready-to-go.`nView completed (chronological), with one-click re-analysis that updates timestamps.`nAll verse analyses still land in 1.1.1_birha.csv exactly as before.`n`n9) Tiny Pseudocode nuggets`nExact verse hits`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`tdef tokenize_punjabi(s):`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    s = unicodedata.normalize("NFC", s.replace("॥"," ").replace("।"," "))`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    s = s.replace("\u200b","").replace("\u200c","").replace("\u200d","")`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    return [w.strip().lower() for w in re.split(r"\s+", s) if w.strip()]`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`tdef find_verses_for_word(xlsx, word_key):`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    df = pd.read_excel(xlsx)`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    rows = []`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    for _, r in df.iterrows():`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t        verse = str(r['Verse'])`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t        tokens = [t for t in tokenize_punjabi(verse)]`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t        if word_key in tokens:`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t            rows.append({`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t                'verse': verse,`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t                'page_number': r.get('Page Number', None)`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t            })`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    # dedup on (norm_verse_key, page)`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    seen = set()`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    out = []`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    for row in rows:`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t        key = (normalize_verse_key(row['verse']), str(row['page_number']))`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t        if key not in seen:`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t            seen.add(key)`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t            out.append(row)`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    return out`nMark completion`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`tdef mark_completed(progress_df, word_key, verse_key):`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    ix = (progress_df['word_key_norm']==word_key) &amp; (progress_df['verse_key']==verse_key)`n`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t`t    progress_df.loc[ix, ['status','completed_at']] = ['completed', datetime.now()]`n`n10) Next Steps with Codex CLI`nImplementation will proceed in a sequential, task-by-task manner using Codex CLI. At each stage:`nCodex will focus on a single defined task from this plan.`nThe implementation for that task will be carried out and validated.`nCodex will then push the branch with the changes.`nCodex will draft a clear PR description summarizing the changes made, assumptions (if any), and the checks performed.`nAfter review and refinement, the next task in sequence will be initiated.`nThis loop ensures that development stays incremental, reviewable, and tightly aligned with the plan while leveraging Codex CLI for version control and documentation.`n`n11) Task Roadmap (for Codex CLI execution)`nThe sequence of tasks to be carried out, one at a time, is as follows:`nCreate launch_word_assessment_dashboard() with three buttons wired (no logic yet).`nImplement tracker helpers (create, load, append) using openpyxl via pandas.`nBuild the lexicon index from 1.1.3 …xlsx and the word-search modal.`nImplement verse-hit list with checkbox selection UI and write entries to Progress.`nAdd the driver that opens the Verse analyzer and updates Progress/Words.`nWire the “Continue” and “Completed” views with their filters and actions.`n`n
